# Create the adventureworks database in PostgreSQL in Docker {#chapter_setup-adventureworks-db}

> NOTE: This chapter doesn't go into the details of *creating* or *restoring* the `adventureworks` database.  For more detail on what's going on behind the scenes, you can examine the step-by-step code in:
>
> ` source('book-src/restore-adventureworks-postgres-on-docker.R') `

> This chapter demonstrates how to:
>
>  * Setup the `adventureworks` database in Docker
>  * Stop and start Docker container to demonstrate persistence
>  * Connect to and disconnect R from the `adventureworks` database
>  * Set up the environment for subsequent chapters

## Overview

In the last chapter we connected to PostgreSQL from R.  Now we set up a "realistic" database named `adventureworks`. There are different approaches to doing this: this chapter sets it up in a way that doesn't show all the Docker details.

These packages are called in this Chapter:
```{r setup, echo=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(DBI)
library(RPostgres)
library(glue)
require(knitr)
library(dbplyr)
library(sqlpetr)
library(bookdown)
library(here)
```

## Verify that Docker is up and running
```{r docker verify}
sp_check_that_docker_is_up()
```

## Clean up if appropriate
Force-remove the `adventureworks` container if it exist (e.g., from a prior runs):
```{r}
sp_docker_remove_container("adventureworks")
```
## Build the pet-sql Docker image

**UPDATE:** For the rest of the book we will be using a Docker image called
`adventureworks`. To save space here in the book, we've created a function
in `sqlpetr` to build this image, called [`sp_make_dvdrental_image`](https://smithjd.github.io/sqlpetr/reference/sp_make_dvdrental_image.html). Vignette [Building the `hsrample` Docker Image
](https://smithjd.github.io/sqlpetr/articles/building-the-dvdrental-docker-image.html) describes the build process.

```{r}
# sp_make_dvdrental_image("postgres-dvdrental")
source(here("book-src", "restore-adventureworks-postgres-on-docker.R"))
```

**UPDATE:** Did it work? We have a function that lists the images into a tibble!

```{r}
sp_docker_start("adventureworks")
sp_docker_images_tibble()  # Doesn't produce the expected output.

```

## Run the pet-sql Docker Image
**UPDATE:** Now we can run the image in a container and connect to the database. To run the
image we use an `sqlpetr` function called [`sp_pg_docker_run`](https://smithjd.github.io/sqlpetr/reference/sp_pg_docker_run.html)

```{r eval= FALSE}
# sp_pg_docker_run(
#   container_name = "adventureworks",
#   image_tag = "adventureworks",
#   postgres_password = "postgres"
# )
```

**UPDATE:** Did it work?
```{r}

sp_docker_containers_tibble()

```

## Connect to PostgreSQL with R

Use the DBI package to connect to the `adventureworks` database in PostgreSQL.  Remember the settings discussion about [keeping passwords hidden][Pause for some security considerations]

```{r }
con <- sp_get_postgres_connection(
  host = "localhost",
  port = 5432,
  user = "postgres",
  password = "postgres",
  dbname = "adventureworks",
  seconds_to_test = 20, connection_tab = TRUE
)
```
For the moment we by-pass some complexity that results from the fact that the `adventureworks` has multiple *schemas* and that we are interested in only one of them, named `adventureworks`.  
```{r}
tbl(con, in_schema("information_schema", "schemata")) %>%
  select(catalog_name, schema_name, schema_owner) %>%
  collect()

```

Schemas will be discussed later on because multiple schemas are the norm in an enterprise database environment, but they are a side issue at this point.  So we switch the order in which PostgreSQL searches for objects with the following SQL code:
```{r}
dbExecute(con, "set search_path to humanresources, public;")

```
With the custom `search_path`, the following command works, but it will fail without out it.
```{r}
dbListTables(con)
```
Same for `dbListFields`:
```{r }
dbListFields(con, "employee")
```

Thus with this search order, the following two produce identical results:
```{r }
tbl(con, in_schema("humanresources", "employee")) %>%
  head()

tbl(con, "employee") %>%
  head()

```


Disconnect from the database:
```{r }
dbDisconnect(con)

```
## Stop and start to demonstrate persistence

Stop the container:
```{r}
sp_docker_stop("adventureworks")
sp_docker_containers_tibble()
```

When we stopped `sql-pet`, it no longer appeared in the tibble. But the
container is still there. `sp_docker_containers_tibble` by default only lists
the *running* containers. But we can use the `list_all` option and see it:

```{r}
sp_docker_containers_tibble(list_all = TRUE)
```


Restart the container and verify that the adventureworks tables are still there:
```{r}
sp_docker_start("adventureworks")
sp_docker_containers_tibble()
```
Connect to the `adventureworks` database in PostgreSQL:
```{r}
con <- sp_get_postgres_connection(
  host = "localhost",
  port = 5432,
  user = "postgres",
  password = "postgres",
  dbname = "adventureworks",
  seconds_to_test = 30
)
```

Check that you can still see the first few rows of the `employeeinfo` table:
```{r}
tbl(con, in_schema("humanresources", "employee")) %>%
  head()

```

## Cleaning up

Always have R disconnect from the database when you're done.
```{r}

dbDisconnect(con)

```

Stop the `sql-pet` container:
```{r}
sp_docker_stop("adventureworks")
```
Show that the container still exists even though it's not running

```{r}
sp_show_all_docker_containers()

```

Next time, you can just use this command to start the container: 

> `sp_docker_start("adventureworks")`

And once stopped, the container can be removed with:

> `sp_check_that_docker_is_up("adventureworks")`

## Using the `sql-pet` container in the rest of the book

After this point in the book, we assume that Docker is up and that we can always start up our *sql-pet database* with:

> `sp_docker_start("adventureworks")`

